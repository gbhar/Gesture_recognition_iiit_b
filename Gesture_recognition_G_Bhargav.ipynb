{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Gesture Recognition**\n",
        "\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ],
      "metadata": {
        "id": "t62N8T2yMOh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from imageio.v2 import imread\n",
        "from skimage.transform import resize\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import Conv3D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.applications import mobilenet"
      ],
      "metadata": {
        "id": "4ZLDH6MtMRxP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ],
      "metadata": {
        "id": "uF9sNMSeMpef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ],
      "metadata": {
        "id": "jTzQbtD9Msg4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Data (Running on Google Colab as Jarvis Ai labs workspace is having py environment issues. Not able to import necessary modules and libraries)"
      ],
      "metadata": {
        "id": "89IIGdHxMyBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNRQFgRXMvOh",
        "outputId": "797adc28-6231-422e-8d9a-c7fe3bc06af8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = np.random.permutation(open('/content/gdrive/My Drive/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/gdrive/My Drive/Project_data/val.csv').readlines())\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "gm_mDj49NEGQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GEnerator**\n",
        "\n",
        "The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with img_idx, y,z and normalization such that you get high accuracy."
      ],
      "metadata": {
        "id": "gyTgyR1iNvPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(source_path, folder_list, batch_size, img_idx, image_height, image_width):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    # img_idx = [1,4,7,10,13,16,19,22,25,28] #create a list of image numbers you want to use for a particular video\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(t)/batch_size) # calculate the number of batches\n",
        "        # left over batches which should be handled separately\n",
        "        leftover_batches = len(t) - num_batches * batch_size\n",
        "\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size, len(img_idx), image_height, image_width, 3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = resize(image, (image_height, image_width))\n",
        "                    batch_data[folder,idx,:,:,0] = (image[:,:,0]) - 104\n",
        "                    batch_data[folder,idx,:,:,1] = (image[:,:,1]) - 117\n",
        "                    batch_data[folder,idx,:,:,2] = (image[:,:,2]) - 123\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        if leftover_batches != 0:\n",
        "            for batch in range(num_batches):\n",
        "                # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "                batch_data = np.zeros((batch_size,len(img_idx),image_height, image_width,3))\n",
        "                # batch_labels is the one hot representation of the output: 10 videos with 5 columns as classes\n",
        "                batch_labels = np.zeros((batch_size,5))\n",
        "                for folder in range(batch_size): # iterate over the batch_size\n",
        "                    imgs = os.listdir(source_path +'/'+t[batch * batch_size + folder].split(';')[0])\n",
        "                    for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "\n",
        "                        image = imageio.imread(source_path +'/'+t[batch * batch_size + folder].split(';')[0] +'/'+imgs[item]).astype(np.float32)\n",
        "                        image = resize(image, (image_height,image_width))\n",
        "\n",
        "                        batch_data[folder,idx,:,:,0] = (image[:,:,0]) - 104\n",
        "                        batch_data[folder,idx,:,:,1] = (image[:,:,1]) - 117\n",
        "                        batch_data[folder,idx,:,:,2] = (image[:,:,2]) - 123\n",
        "\n",
        "                    #Fill the one hot encoding stuff where we maintain the label\n",
        "                    batch_labels[folder, int(t[batch * batch_size + folder].split(';')[2])] = 1\n",
        "                yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do"
      ],
      "metadata": {
        "id": "NR1Aru-NNpLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/gdrive/My Drive/Project_data/train'\n",
        "val_path = '/content/gdrive/My Drive/Project_data/val'\n",
        "model_path_prefix = '/content/gdrive/My Drive/Models/'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 15 # choose the number of epochs\n",
        "print ('# epochs =', num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhALaSgcOIm6",
        "outputId": "719fb2d4-f3da-481a-d202-927befa0ff72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 1\n",
        "test_gen = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "d = next(test_gen)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj5Wlw73OLac",
        "outputId": "600fcc50-e25b-4fac-a3b8-84aac283fa0b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/My Drive/Project_data/train ; batch size = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 - 50x50 - No Dropout - Layers [16 > 32 > 64 >> 128 >> 5]"
      ],
      "metadata": {
        "id": "PuIFjbNCPQcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 1\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBHEjrt_OOV8",
        "outputId": "c5260f19-8547-46a3-c157-12cc05214f6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 10, 50, 50, 16)    1312      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 5, 25, 25, 16)     0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 5, 25, 25, 16)     64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 5, 25, 25, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 2, 12, 12, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 2, 12, 12, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 2, 12, 12, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 1, 6, 6, 64)       0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 1, 6, 6, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 366661 (1.40 MB)\n",
            "Trainable params: 366437 (1.40 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ],
      "metadata": {
        "id": "Gc_TSARVPnLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LxaKfSOPp73",
        "outputId": "76d41e87-d603-47e8-c2b3-bfb62bbadd50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/My Drive/Project_data/train ; batch size = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-579c15b5d096>:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 1.9778 - categorical_accuracy: 0.3469Source path =  /content/gdrive/My Drive/Project_data/val ; batch size = 1\n",
            "\n",
            "Epoch 1: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00001-1.97775-0.34691-1.85271-0.39000.h5\n",
            "663/663 [==============================] - 2730s 4s/step - loss: 1.9778 - categorical_accuracy: 0.3469 - val_loss: 1.8527 - val_categorical_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "663/663 [==============================] - ETA: 0s - loss: 1.2469 - categorical_accuracy: 0.5204\n",
            "Epoch 2: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00002-1.24686-0.52036-1.59103-0.46000.h5\n",
            "663/663 [==============================] - 193s 291ms/step - loss: 1.2469 - categorical_accuracy: 0.5204 - val_loss: 1.5910 - val_categorical_accuracy: 0.4600 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.9524 - categorical_accuracy: 0.6199\n",
            "Epoch 3: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00003-0.95242-0.61991-1.45746-0.52000.h5\n",
            "663/663 [==============================] - 195s 294ms/step - loss: 0.9524 - categorical_accuracy: 0.6199 - val_loss: 1.4575 - val_categorical_accuracy: 0.5200 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.6963 - categorical_accuracy: 0.7406\n",
            "Epoch 4: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00004-0.69630-0.74057-1.75858-0.51000.h5\n",
            "663/663 [==============================] - 191s 288ms/step - loss: 0.6963 - categorical_accuracy: 0.7406 - val_loss: 1.7586 - val_categorical_accuracy: 0.5100 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.6153 - categorical_accuracy: 0.7858\n",
            "Epoch 5: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00005-0.61529-0.78582-1.50718-0.51000.h5\n",
            "663/663 [==============================] - 197s 297ms/step - loss: 0.6153 - categorical_accuracy: 0.7858 - val_loss: 1.5072 - val_categorical_accuracy: 0.5100 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.4389 - categorical_accuracy: 0.8492\n",
            "Epoch 6: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00006-0.43888-0.84917-1.51155-0.61000.h5\n",
            "663/663 [==============================] - 194s 293ms/step - loss: 0.4389 - categorical_accuracy: 0.8492 - val_loss: 1.5115 - val_categorical_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2589 - categorical_accuracy: 0.9065\n",
            "Epoch 7: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00007-0.25890-0.90649-1.77860-0.55000.h5\n",
            "663/663 [==============================] - 206s 310ms/step - loss: 0.2589 - categorical_accuracy: 0.9065 - val_loss: 1.7786 - val_categorical_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2007 - categorical_accuracy: 0.9246\n",
            "Epoch 8: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00008-0.20067-0.92459-2.29295-0.58000.h5\n",
            "663/663 [==============================] - 196s 296ms/step - loss: 0.2007 - categorical_accuracy: 0.9246 - val_loss: 2.2930 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.1660 - categorical_accuracy: 0.9427\n",
            "Epoch 9: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00009-0.16604-0.94268-2.26721-0.53000.h5\n",
            "663/663 [==============================] - 187s 282ms/step - loss: 0.1660 - categorical_accuracy: 0.9427 - val_loss: 2.2672 - val_categorical_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2125 - categorical_accuracy: 0.9261\n",
            "Epoch 10: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00010-0.21251-0.92609-2.69963-0.57000.h5\n",
            "663/663 [==============================] - 187s 282ms/step - loss: 0.2125 - categorical_accuracy: 0.9261 - val_loss: 2.6996 - val_categorical_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.2256 - categorical_accuracy: 0.9261\n",
            "Epoch 11: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00011-0.22565-0.92609-1.81720-0.63000.h5\n",
            "663/663 [==============================] - 187s 283ms/step - loss: 0.2256 - categorical_accuracy: 0.9261 - val_loss: 1.8172 - val_categorical_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.0212 - categorical_accuracy: 0.9940\n",
            "Epoch 12: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00012-0.02118-0.99397-1.86645-0.63000.h5\n",
            "663/663 [==============================] - 190s 287ms/step - loss: 0.0212 - categorical_accuracy: 0.9940 - val_loss: 1.8664 - val_categorical_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 1.0000\n",
            "Epoch 13: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00013-0.00245-1.00000-1.81017-0.58000.h5\n",
            "663/663 [==============================] - 191s 288ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 1.8102 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 9.9660e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 14: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00014-0.00100-1.00000-2.10574-0.60000.h5\n",
            "663/663 [==============================] - 190s 286ms/step - loss: 9.9660e-04 - categorical_accuracy: 1.0000 - val_loss: 2.1057 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "663/663 [==============================] - ETA: 0s - loss: 6.3448e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 15: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00015-0.00063-1.00000-1.95364-0.58000.h5\n",
            "663/663 [==============================] - 191s 289ms/step - loss: 6.3448e-04 - categorical_accuracy: 1.0000 - val_loss: 1.9536 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79afe97705e0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 - 100x100 - No Dropout - Layers [16 > 32 > 64 >> 128 >> 5]"
      ],
      "metadata": {
        "id": "3cuvtjPtUp6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 100\n",
        "image_width = 100\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZoeBb9GUsgA",
        "outputId": "6668887d-79a2-4f7c-cf71-5fdba7061f3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_3 (Conv3D)           (None, 10, 100, 100, 16   1312      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPoolin  (None, 5, 50, 50, 16)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 5, 50, 50, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 5, 50, 50, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPoolin  (None, 2, 25, 25, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 2, 25, 25, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 2, 25, 25, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPoolin  (None, 1, 12, 12, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 1, 12, 12, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1251397 (4.77 MB)\n",
            "Trainable params: 1251173 (4.77 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOdel Training"
      ],
      "metadata": {
        "id": "irdmbpr4U1la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wOzne1BU28A",
        "outputId": "044ec3a8-a470-4e63-fc86-159318aee720"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-11-579c15b5d096>:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/My Drive/Project_data/train ; batch size = 32\n",
            "Epoch 1/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.6142 - categorical_accuracy: 0.4911 Source path =  /content/gdrive/My Drive/Project_data/val ; batch size = 32\n",
            "\n",
            "Epoch 1: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00001-1.61423-0.49107-30.87673-0.27344.h5\n",
            "21/21 [==============================] - 345s 16s/step - loss: 1.6142 - categorical_accuracy: 0.4911 - val_loss: 30.8767 - val_categorical_accuracy: 0.2734 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5059 - categorical_accuracy: 0.8110 \n",
            "Epoch 2: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00002-0.50594-0.81101-27.26493-0.31250.h5\n",
            "21/21 [==============================] - 327s 16s/step - loss: 0.5059 - categorical_accuracy: 0.8110 - val_loss: 27.2649 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1724 - categorical_accuracy: 0.9375 \n",
            "Epoch 3: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00003-0.17244-0.93750-18.34144-0.28906.h5\n",
            "21/21 [==============================] - 319s 15s/step - loss: 0.1724 - categorical_accuracy: 0.9375 - val_loss: 18.3414 - val_categorical_accuracy: 0.2891 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0356 - categorical_accuracy: 0.9955 \n",
            "Epoch 4: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00004-0.03562-0.99554-11.17307-0.35156.h5\n",
            "21/21 [==============================] - 327s 16s/step - loss: 0.0356 - categorical_accuracy: 0.9955 - val_loss: 11.1731 - val_categorical_accuracy: 0.3516 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0224 - categorical_accuracy: 0.9970 \n",
            "Epoch 5: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00005-0.02243-0.99702-8.89164-0.29688.h5\n",
            "21/21 [==============================] - 313s 15s/step - loss: 0.0224 - categorical_accuracy: 0.9970 - val_loss: 8.8916 - val_categorical_accuracy: 0.2969 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0076 - categorical_accuracy: 1.0000 \n",
            "Epoch 6: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00006-0.00764-1.00000-4.94104-0.37500.h5\n",
            "21/21 [==============================] - 328s 16s/step - loss: 0.0076 - categorical_accuracy: 1.0000 - val_loss: 4.9410 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0034 - categorical_accuracy: 1.0000 \n",
            "Epoch 7: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00007-0.00344-1.00000-3.10868-0.39062.h5\n",
            "21/21 [==============================] - 330s 16s/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 3.1087 - val_categorical_accuracy: 0.3906 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 1.0000 \n",
            "Epoch 8: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00008-0.00216-1.00000-2.16040-0.52344.h5\n",
            "21/21 [==============================] - 346s 17s/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 2.1604 - val_categorical_accuracy: 0.5234 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 1.0000 \n",
            "Epoch 9: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00009-0.00196-1.00000-1.52688-0.60156.h5\n",
            "21/21 [==============================] - 316s 15s/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 1.5269 - val_categorical_accuracy: 0.6016 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000 \n",
            "Epoch 10: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00010-0.00132-1.00000-1.08952-0.64062.h5\n",
            "21/21 [==============================] - 326s 16s/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 1.0895 - val_categorical_accuracy: 0.6406 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0011 - categorical_accuracy: 1.0000 \n",
            "Epoch 11: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00011-0.00115-1.00000-0.78203-0.72656.h5\n",
            "21/21 [==============================] - 316s 15s/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.7820 - val_categorical_accuracy: 0.7266 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 8.4775e-04 - categorical_accuracy: 1.0000 \n",
            "Epoch 12: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00012-0.00085-1.00000-0.67242-0.74219.h5\n",
            "21/21 [==============================] - 368s 17s/step - loss: 8.4775e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6724 - val_categorical_accuracy: 0.7422 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 9.3607e-04 - categorical_accuracy: 1.0000 \n",
            "Epoch 13: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00013-0.00094-1.00000-0.63061-0.77344.h5\n",
            "21/21 [==============================] - 322s 15s/step - loss: 9.3607e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6306 - val_categorical_accuracy: 0.7734 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 8.7812e-04 - categorical_accuracy: 1.0000 \n",
            "Epoch 14: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00014-0.00088-1.00000-0.59848-0.76562.h5\n",
            "21/21 [==============================] - 323s 15s/step - loss: 8.7812e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5985 - val_categorical_accuracy: 0.7656 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 5.9801e-04 - categorical_accuracy: 1.0000 \n",
            "Epoch 15: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00015-0.00060-1.00000-0.39932-0.87500.h5\n",
            "21/21 [==============================] - 320s 15s/step - loss: 5.9801e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3993 - val_categorical_accuracy: 0.8750 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79b0141a2770>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3 - 100x100 - Dropout 0.5 - Layers [16 > 32 > 64 >> 128 >> 5]"
      ],
      "metadata": {
        "id": "tPjtLrTJoZFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 100\n",
        "image_width = 100\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(16, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEIsXzZ_U6yl",
        "outputId": "6e30138d-3f8c-4baa-d40f-d9695fd55bbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_6 (Conv3D)           (None, 10, 100, 100, 16   1312      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d_6 (MaxPoolin  (None, 5, 50, 50, 16)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 50, 50, 16)     0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 5, 50, 50, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_7 (Conv3D)           (None, 5, 50, 50, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_7 (MaxPoolin  (None, 2, 25, 25, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 25, 25, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 2, 25, 25, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_8 (Conv3D)           (None, 2, 25, 25, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_8 (MaxPoolin  (None, 1, 12, 12, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 12, 12, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 1, 12, 12, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1251397 (4.77 MB)\n",
            "Trainable params: 1251173 (4.77 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5FaA8iSodah",
        "outputId": "ff4274f8-03d9-4ad3-9643-2379cf3a35d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-13-579c15b5d096>:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/My Drive/Project_data/train ; batch size = 32\n",
            "Epoch 1/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.0192 - categorical_accuracy: 0.3557 Source path =  /content/gdrive/My Drive/Project_data/val ; batch size = 32\n",
            "\n",
            "Epoch 1: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00001-2.01924-0.35565-16.15968-0.20312.h5\n",
            "21/21 [==============================] - 328s 16s/step - loss: 2.0192 - categorical_accuracy: 0.3557 - val_loss: 16.1597 - val_categorical_accuracy: 0.2031 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4511 - categorical_accuracy: 0.4628 \n",
            "Epoch 2: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00002-1.45109-0.46280-5.43972-0.21094.h5\n",
            "21/21 [==============================] - 323s 15s/step - loss: 1.4511 - categorical_accuracy: 0.4628 - val_loss: 5.4397 - val_categorical_accuracy: 0.2109 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.2884 - categorical_accuracy: 0.4598 \n",
            "Epoch 3: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00003-1.28839-0.45982-1.47960-0.38281.h5\n",
            "21/21 [==============================] - 323s 15s/step - loss: 1.2884 - categorical_accuracy: 0.4598 - val_loss: 1.4796 - val_categorical_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0613 - categorical_accuracy: 0.5655 \n",
            "Epoch 4: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00004-1.06131-0.56548-1.17999-0.53906.h5\n",
            "21/21 [==============================] - 321s 15s/step - loss: 1.0613 - categorical_accuracy: 0.5655 - val_loss: 1.1800 - val_categorical_accuracy: 0.5391 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9355 - categorical_accuracy: 0.6071 \n",
            "Epoch 5: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00005-0.93546-0.60714-1.38399-0.49219.h5\n",
            "21/21 [==============================] - 320s 15s/step - loss: 0.9355 - categorical_accuracy: 0.6071 - val_loss: 1.3840 - val_categorical_accuracy: 0.4922 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8650 - categorical_accuracy: 0.6533 \n",
            "Epoch 6: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00006-0.86502-0.65327-1.67958-0.43750.h5\n",
            "21/21 [==============================] - 321s 15s/step - loss: 0.8650 - categorical_accuracy: 0.6533 - val_loss: 1.6796 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8516 - categorical_accuracy: 0.6756 \n",
            "Epoch 7: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00007-0.85163-0.67560-1.81468-0.47656.h5\n",
            "21/21 [==============================] - 322s 15s/step - loss: 0.8516 - categorical_accuracy: 0.6756 - val_loss: 1.8147 - val_categorical_accuracy: 0.4766 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.7489 - categorical_accuracy: 0.7232 \n",
            "Epoch 8: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00008-0.74893-0.72321-1.98024-0.39844.h5\n",
            "21/21 [==============================] - 322s 15s/step - loss: 0.7489 - categorical_accuracy: 0.7232 - val_loss: 1.9802 - val_categorical_accuracy: 0.3984 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.7197 - categorical_accuracy: 0.7292 \n",
            "Epoch 9: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00009-0.71974-0.72917-1.89737-0.43750.h5\n",
            "21/21 [==============================] - 323s 15s/step - loss: 0.7197 - categorical_accuracy: 0.7292 - val_loss: 1.8974 - val_categorical_accuracy: 0.4375 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.7208 - categorical_accuracy: 0.7113 \n",
            "Epoch 10: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00010-0.72080-0.71131-2.50926-0.39844.h5\n",
            "21/21 [==============================] - 330s 16s/step - loss: 0.7208 - categorical_accuracy: 0.7113 - val_loss: 2.5093 - val_categorical_accuracy: 0.3984 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.6218 - categorical_accuracy: 0.7396 \n",
            "Epoch 11: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00011-0.62183-0.73958-3.16261-0.38281.h5\n",
            "21/21 [==============================] - 325s 16s/step - loss: 0.6218 - categorical_accuracy: 0.7396 - val_loss: 3.1626 - val_categorical_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.6288 - categorical_accuracy: 0.7500 \n",
            "Epoch 12: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00012-0.62885-0.75000-4.91514-0.35938.h5\n",
            "21/21 [==============================] - 321s 15s/step - loss: 0.6288 - categorical_accuracy: 0.7500 - val_loss: 4.9151 - val_categorical_accuracy: 0.3594 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.6197 - categorical_accuracy: 0.7664 \n",
            "Epoch 13: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00013-0.61974-0.76637-4.77138-0.31250.h5\n",
            "21/21 [==============================] - 321s 15s/step - loss: 0.6197 - categorical_accuracy: 0.7664 - val_loss: 4.7714 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5563 - categorical_accuracy: 0.7768 \n",
            "Epoch 14: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00014-0.55630-0.77679-4.13606-0.35938.h5\n",
            "21/21 [==============================] - 321s 15s/step - loss: 0.5563 - categorical_accuracy: 0.7768 - val_loss: 4.1361 - val_categorical_accuracy: 0.3594 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5246 - categorical_accuracy: 0.7798 \n",
            "Epoch 15: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0810_58_58.029983/model-00015-0.52461-0.77976-6.15084-0.33594.h5\n",
            "21/21 [==============================] - 322s 15s/step - loss: 0.5246 - categorical_accuracy: 0.7798 - val_loss: 6.1508 - val_categorical_accuracy: 0.3359 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79b013ea4460>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4 - 100x100 - Dropout 0.5 - Layers [32 > 64 > 128 >> 256 >> 5]"
      ],
      "metadata": {
        "id": "cSvlXvFg7Z-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 100\n",
        "image_width = 100\n",
        "batch_size = 64\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(128, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OLdoY91ohpY",
        "outputId": "4b414e7f-a6a9-4819-c80b-d848646b1beb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 10, 100, 100, 32   2624      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 5, 50, 50, 32)     0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 50, 50, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 5, 50, 50, 32)     128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 5, 50, 50, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 2, 25, 25, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 25, 25, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 2, 25, 25, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 2, 25, 25, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 1, 12, 12, 128)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 12, 12, 128)    0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 1, 12, 12, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18432)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               4718848   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5000325 (19.07 MB)\n",
            "Trainable params: 4999877 (19.07 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OK95XXU7dsC",
        "outputId": "d12c6899-f05e-4729-e9fa-81f5a306af68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-10-b48246a4c71f>:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/My Drive/Project_data/train ; batch size = 64\n",
            "Epoch 1/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.3193 - categorical_accuracy: 0.3395  Source path =  /content/gdrive/My Drive/Project_data/val ; batch size = 64\n",
            "\n",
            "Epoch 1: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00001-2.31928-0.33949-26.31317-0.23438.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/11 [==============================] - 2037s 200s/step - loss: 2.3193 - categorical_accuracy: 0.3395 - val_loss: 26.3132 - val_categorical_accuracy: 0.2344 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4331 - categorical_accuracy: 0.4815 \n",
            "Epoch 2: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00002-1.43314-0.48153-33.85950-0.22656.h5\n",
            "11/11 [==============================] - 565s 52s/step - loss: 1.4331 - categorical_accuracy: 0.4815 - val_loss: 33.8595 - val_categorical_accuracy: 0.2266 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1318 - categorical_accuracy: 0.5866 \n",
            "Epoch 3: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00003-1.13179-0.58665-21.19583-0.25000.h5\n",
            "11/11 [==============================] - 565s 52s/step - loss: 1.1318 - categorical_accuracy: 0.5866 - val_loss: 21.1958 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8929 - categorical_accuracy: 0.6534 \n",
            "Epoch 4: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00004-0.89292-0.65341-19.75599-0.25781.h5\n",
            "11/11 [==============================] - 570s 52s/step - loss: 0.8929 - categorical_accuracy: 0.6534 - val_loss: 19.7560 - val_categorical_accuracy: 0.2578 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8610 - categorical_accuracy: 0.6662 \n",
            "Epoch 5: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00005-0.86095-0.66619-13.77521-0.23438.h5\n",
            "11/11 [==============================] - 535s 49s/step - loss: 0.8610 - categorical_accuracy: 0.6662 - val_loss: 13.7752 - val_categorical_accuracy: 0.2344 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7770 - categorical_accuracy: 0.6847 \n",
            "Epoch 6: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00006-0.77702-0.68466-6.82403-0.29688.h5\n",
            "11/11 [==============================] - 534s 49s/step - loss: 0.7770 - categorical_accuracy: 0.6847 - val_loss: 6.8240 - val_categorical_accuracy: 0.2969 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6691 - categorical_accuracy: 0.7386 \n",
            "Epoch 7: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00007-0.66908-0.73864-3.89990-0.37500.h5\n",
            "11/11 [==============================] - 565s 52s/step - loss: 0.6691 - categorical_accuracy: 0.7386 - val_loss: 3.8999 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5809 - categorical_accuracy: 0.7841 \n",
            "Epoch 8: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00008-0.58087-0.78409-2.75153-0.42969.h5\n",
            "11/11 [==============================] - 567s 52s/step - loss: 0.5809 - categorical_accuracy: 0.7841 - val_loss: 2.7515 - val_categorical_accuracy: 0.4297 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5235 - categorical_accuracy: 0.7926 \n",
            "Epoch 9: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00009-0.52347-0.79261-1.48759-0.56250.h5\n",
            "11/11 [==============================] - 566s 52s/step - loss: 0.5235 - categorical_accuracy: 0.7926 - val_loss: 1.4876 - val_categorical_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.8125 \n",
            "Epoch 10: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00010-0.48113-0.81250-1.46459-0.57812.h5\n",
            "11/11 [==============================] - 550s 50s/step - loss: 0.4811 - categorical_accuracy: 0.8125 - val_loss: 1.4646 - val_categorical_accuracy: 0.5781 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4357 - categorical_accuracy: 0.8153 \n",
            "Epoch 11: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00011-0.43573-0.81534-1.29740-0.68750.h5\n",
            "11/11 [==============================] - 566s 52s/step - loss: 0.4357 - categorical_accuracy: 0.8153 - val_loss: 1.2974 - val_categorical_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3469 - categorical_accuracy: 0.8594 \n",
            "Epoch 12: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00012-0.34694-0.85938-1.56097-0.68750.h5\n",
            "11/11 [==============================] - 544s 50s/step - loss: 0.3469 - categorical_accuracy: 0.8594 - val_loss: 1.5610 - val_categorical_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3216 - categorical_accuracy: 0.8793 \n",
            "Epoch 13: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00013-0.32161-0.87926-1.11509-0.71875.h5\n",
            "11/11 [==============================] - 553s 51s/step - loss: 0.3216 - categorical_accuracy: 0.8793 - val_loss: 1.1151 - val_categorical_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2837 - categorical_accuracy: 0.8864 \n",
            "Epoch 14: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00014-0.28371-0.88636-1.54943-0.64844.h5\n",
            "11/11 [==============================] - 545s 50s/step - loss: 0.2837 - categorical_accuracy: 0.8864 - val_loss: 1.5494 - val_categorical_accuracy: 0.6484 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2376 - categorical_accuracy: 0.9091 \n",
            "Epoch 15: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00015-0.23760-0.90909-2.04923-0.64062.h5\n",
            "11/11 [==============================] - 569s 53s/step - loss: 0.2376 - categorical_accuracy: 0.9091 - val_loss: 2.0492 - val_categorical_accuracy: 0.6406 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 5 - 50x50 - Dropout 0.5 - Layers [32 > 64 > 128 >> 256 >> 5]"
      ],
      "metadata": {
        "id": "sdvaFMDrghhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = list(range(1,30,3))\n",
        "frames = len(img_idx)\n",
        "image_height = 50\n",
        "image_width = 50\n",
        "batch_size = 64\n",
        "num_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, (3,3,3), padding='same', input_shape=(frames, image_height, image_width, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(128, (3,3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimiser = \"adam\"\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYtvIaPIggQo",
        "outputId": "dfbe0119-982b-4f7a-f9a3-9f47ddb4a920"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_3 (Conv3D)           (None, 10, 50, 50, 32)    2624      \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPoolin  (None, 5, 25, 25, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5, 25, 25, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 5, 25, 25, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 5, 25, 25, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPoolin  (None, 2, 12, 12, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2, 12, 12, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 2, 12, 12, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 2, 12, 12, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPoolin  (None, 1, 6, 6, 128)      0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 1, 6, 6, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               1179904   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1461381 (5.57 MB)\n",
            "Trainable params: 1460933 (5.57 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_idx, image_height, image_width)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_idx, image_height, image_width)\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_path_prefix + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRiR0aYngo1O",
        "outputId": "6a7b1159-26ae-4332-fdaf-9d64e08309a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-12-b48246a4c71f>:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/My Drive/Project_data/train ; batch size = 64\n",
            "Epoch 1/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.2167 - categorical_accuracy: 0.3295 Source path =  /content/gdrive/My Drive/Project_data/val ; batch size = 64\n",
            "\n",
            "Epoch 1: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00001-2.21672-0.32955-29.89091-0.20312.h5\n",
            "11/11 [==============================] - 234s 22s/step - loss: 2.2167 - categorical_accuracy: 0.3295 - val_loss: 29.8909 - val_categorical_accuracy: 0.2031 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.7137 - categorical_accuracy: 0.4347 \n",
            "Epoch 2: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00002-1.71370-0.43466-24.41684-0.21875.h5\n",
            "11/11 [==============================] - 195s 18s/step - loss: 1.7137 - categorical_accuracy: 0.4347 - val_loss: 24.4168 - val_categorical_accuracy: 0.2188 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.4586 - categorical_accuracy: 0.4645 \n",
            "Epoch 3: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00003-1.45857-0.46449-17.75080-0.20312.h5\n",
            "11/11 [==============================] - 192s 18s/step - loss: 1.4586 - categorical_accuracy: 0.4645 - val_loss: 17.7508 - val_categorical_accuracy: 0.2031 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.2549 - categorical_accuracy: 0.4886 \n",
            "Epoch 4: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00004-1.25495-0.48864-10.80797-0.24219.h5\n",
            "11/11 [==============================] - 193s 18s/step - loss: 1.2549 - categorical_accuracy: 0.4886 - val_loss: 10.8080 - val_categorical_accuracy: 0.2422 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1342 - categorical_accuracy: 0.5526 \n",
            "Epoch 5: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00005-1.13421-0.55256-7.10164-0.21875.h5\n",
            "11/11 [==============================] - 193s 18s/step - loss: 1.1342 - categorical_accuracy: 0.5526 - val_loss: 7.1016 - val_categorical_accuracy: 0.2188 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0458 - categorical_accuracy: 0.5668 \n",
            "Epoch 6: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00006-1.04584-0.56676-5.99971-0.25781.h5\n",
            "11/11 [==============================] - 193s 18s/step - loss: 1.0458 - categorical_accuracy: 0.5668 - val_loss: 5.9997 - val_categorical_accuracy: 0.2578 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.9712 - categorical_accuracy: 0.5838 \n",
            "Epoch 7: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00007-0.97123-0.58381-3.43278-0.29688.h5\n",
            "11/11 [==============================] - 194s 18s/step - loss: 0.9712 - categorical_accuracy: 0.5838 - val_loss: 3.4328 - val_categorical_accuracy: 0.2969 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8906 - categorical_accuracy: 0.6491 \n",
            "Epoch 8: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00008-0.89065-0.64915-2.74909-0.38281.h5\n",
            "11/11 [==============================] - 194s 18s/step - loss: 0.8906 - categorical_accuracy: 0.6491 - val_loss: 2.7491 - val_categorical_accuracy: 0.3828 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8754 - categorical_accuracy: 0.6520 \n",
            "Epoch 9: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00009-0.87537-0.65199-1.47810-0.53125.h5\n",
            "11/11 [==============================] - 200s 19s/step - loss: 0.8754 - categorical_accuracy: 0.6520 - val_loss: 1.4781 - val_categorical_accuracy: 0.5312 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8357 - categorical_accuracy: 0.6705 \n",
            "Epoch 10: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00010-0.83568-0.67045-1.47908-0.49219.h5\n",
            "11/11 [==============================] - 198s 18s/step - loss: 0.8357 - categorical_accuracy: 0.6705 - val_loss: 1.4791 - val_categorical_accuracy: 0.4922 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7908 - categorical_accuracy: 0.6960 \n",
            "Epoch 11: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00011-0.79083-0.69602-2.30995-0.46875.h5\n",
            "11/11 [==============================] - 196s 18s/step - loss: 0.7908 - categorical_accuracy: 0.6960 - val_loss: 2.3100 - val_categorical_accuracy: 0.4688 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7764 - categorical_accuracy: 0.7003 \n",
            "Epoch 12: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00012-0.77642-0.70028-1.02654-0.58594.h5\n",
            "11/11 [==============================] - 193s 18s/step - loss: 0.7764 - categorical_accuracy: 0.7003 - val_loss: 1.0265 - val_categorical_accuracy: 0.5859 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7503 - categorical_accuracy: 0.7017 \n",
            "Epoch 13: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00013-0.75027-0.70170-0.74719-0.73438.h5\n",
            "11/11 [==============================] - 194s 18s/step - loss: 0.7503 - categorical_accuracy: 0.7017 - val_loss: 0.7472 - val_categorical_accuracy: 0.7344 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6762 - categorical_accuracy: 0.7457 \n",
            "Epoch 14: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00014-0.67621-0.74574-0.87610-0.68750.h5\n",
            "11/11 [==============================] - 196s 18s/step - loss: 0.6762 - categorical_accuracy: 0.7457 - val_loss: 0.8761 - val_categorical_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6673 - categorical_accuracy: 0.7230 \n",
            "Epoch 15: saving model to /content/gdrive/My Drive/Models/model_init_2024-07-0905_05_47.526708/model-00015-0.66729-0.72301-0.83798-0.70312.h5\n",
            "11/11 [==============================] - 199s 18s/step - loss: 0.6673 - categorical_accuracy: 0.7230 - val_loss: 0.8380 - val_categorical_accuracy: 0.7031 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZKbe2SrgtJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}